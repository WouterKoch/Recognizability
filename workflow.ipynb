{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizability bias in citizen science photographs\n",
    "This notebook executes all steps required to train a number of species recognition models based on GBIF data, and analyzes the relationship between species specific performance, citizen science data availability, and species characteristics.\n",
    "\n",
    "## Overview\n",
    "- Load and set settings for the setup:\n",
    "    - Tensorflow settings, directory paths\n",
    "    - Numbers of datasets, dataset sizes, splits, steps \n",
    "- Explore the data:\n",
    "    - Load a GBIF Darwin Core Archive (DwCA)\n",
    "    - Given the settings, summarize what a division per taxonomic rank would provide in terms of training data\n",
    "- Prepare the data:\n",
    "    - Based on a chosen number of species per group and taxon rank, make the groups based on the DwCA\n",
    "- Train the models:\n",
    "    - Find each job and train a model for it\n",
    "- Evaluate the models:\n",
    "    - Use the test data put aside at the data preparation step to evaluate performances\n",
    "    - Save all performance indicators to a central file\n",
    "- Gather metrics based on annotation, biological traits, and citizen science data\n",
    "    - Save a number of plots based on these metrics\n",
    "    - Train and evaluate LASSO models\n",
    "    - Gather other metrics for manuscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General settings\n",
    "- Make sure you have an .env file in the root directory. See the readme for details\n",
    "- The DwCA file is assumed to contain only observations with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the env variables from the file \".env\"\n",
    "dwca_file = os.path.join(os.getenv('STORAGE_DIR'), 'GBIF.zip')  # The path to the DwCA file with all data.\n",
    "\n",
    "train_val_test_threshold = 220  # The minimum number of observations needed per species for train + validation + test\n",
    "train_val_threshold = 200  # The minimum number of observations needed per species for train + validation (for the first, largest test set)\n",
    "reduced_factor = .5  # Every time the number of observations is reduced, it is reduced to this proportion of the previous amount\n",
    "validation_proportion = .1  # The proportion of observations of the train_val set reserved for validation\n",
    "groups = 12  # The number of taxon groups to generate and compare between\n",
    "observations_minimum = train_val_threshold  # The smallest subset of observations to train models on. Equal to the largest set so that only the max size is trained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script reports the results of grouping on any taxonomic level:\n",
    "\n",
    "- How many groups can be made based on the threshold provided, out of the total groups within that level, and how many species would the smallest groups contain.\n",
    "- It also creates csv files with counts per species, and species per taxonomic group.\n",
    "\n",
    "This step provides no direct input for any following steps, and is meant to help you choose the settings in the next step. It does return the created species csv file for subsequent use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.grouping import propse_groups\n",
    "species_csv = propse_groups(dwca_file, train_val_test_threshold, groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dataset we used, the rank of order gives the best division, with at least 18 species per order, so this is the level we will use. Retrieve the relevant taxon groups, and create all training jobs for all taxa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our dataset, we choose the level of order, giving a minimum of 18 species\n",
    "from Scripts.create_jobs import create_jobs\n",
    "from Scripts.grouping import get_groups\n",
    "\n",
    "number_of_species = 18\n",
    "taxonlevel = 'order'\n",
    "\n",
    "grouping_csv = get_groups(dwca_file, train_val_test_threshold, number_of_species, taxonlevel)\n",
    "create_jobs(0, train_val_threshold, reduced_factor, validation_proportion, grouping_csv, species_csv, dwca_file, observations_minimum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Train the models defined in the job creation step. If a model exists, this will be skipped. Training will take a long time depending on your hardware, number of models and dataset sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.train import train_models\n",
    "train_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model evaluation\n",
    "\n",
    "Evaluation requires a \"Species (total).csv\", containing a \"Taxon\" and a \"Number of species\" column (species per taxon group for the whole area of interest). The code below generates this file for a Norwegian context if it does not exist already, based on files retrieved from http://www2.artsdatabanken.no/artsnavn/Contentpages/Eksport.aspx. This tool is as generic as possible, expecting a folder of csv files. Some tweaking will be required for other contexts.\n",
    "\n",
    "All models generated in the previous step are now evaluated using the test sets separated in the data preparation step. This will take a while. When that is done, all performance and bias metrics needed will be collected and stored in .csv files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.evaluate import evaluate\n",
    "from Tools.count_species_per_taxon import count_species_per_taxon\n",
    "\n",
    "count_species_per_taxon(\n",
    "        encoding='cp1252',\n",
    "        sep=';',\n",
    "        output_file='Species (total).csv',\n",
    "        grouping_csv=grouping_csv,\n",
    "        language='no'\n",
    "    )\n",
    "    \n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve all relevant stats for those species and save as a .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.retrieve_species_characteristics import retrieve\n",
    "import pandas as pd\n",
    "\n",
    "bird_species = []\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getenv(\"STORAGE_DIR\"), \"GBIF - observations per species.csv\"))\n",
    "df = df[df[\"order\"].isin([\"Anseriformes\", \"Charadriiformes\", \"Passeriformes\"])]\n",
    "\n",
    "bird_species = df[\"scientificName\"].to_list()\n",
    "retrieve(bird_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get annotations from Label Studio API, the number of images per observation with images, and gather all data in a central csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools.get_annotation_stats import get_annotation_stats\n",
    "from Scripts.regression import collect_data, img_per_obs\n",
    "\n",
    "get_annotation_stats(folder=os.environ[\"STORAGE_DIR\"], api=os.environ[\"ANNOTATION_API\"], token=os.environ[\"ANNOTATION_TOKEN\"], pixels=299)\n",
    "img_per_obs(os.path.join(os.environ[\"STORAGE_DIR\"], \"GBIF.zip\"), os.environ[\"STORAGE_DIR\"])\n",
    "collect_data(folder=os.environ[\"STORAGE_DIR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plots for the manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.plots import collected_stats_scatter, collected_stats_slopes\n",
    "\n",
    "collected_stats_scatter(os.environ[\"STORAGE_DIR\"], \"out.csv\", os.path.join(os.environ[\"STORAGE_DIR\"], \"Graphs\"), \"svg\", \"Images (log)\", \"F1 (mean)\",\n",
    "                        taxa=[\"Anseriformes\", \"Charadriiformes\", \"Passeriformes\"], highlight=[\"Anser serrirostris\", \"Aix galericulata\", \"Larus cachinnans\", \"Charadrius morinellus\", \"Linaria flavirostris\", \"Perisoreus infaustus\"])\n",
    "\n",
    "\n",
    "collected_stats_slopes(os.environ[\"STORAGE_DIR\"], \"out.csv\", os.path.join(os.environ[\"STORAGE_DIR\"], \"Graphs\"), \"svg\", \"Images (log)\", \"F1 (mean)\",\n",
    "                            taxa=[\"Coleoptera\", \"Diptera\", \"Lepidoptera\", \"Odonata\", \"Lecanorales\", \"Agaricales\", \"Polyporales\", \"Asterales\", \"Asparagales\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather metrics (using the scatterplots with regressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_stats_scatter(os.environ[\"STORAGE_DIR\"], \"out.csv\", os.path.join(os.environ[\"STORAGE_DIR\"], \"Graphs\"), \"png\", \"Images (log)\", \"F1 (mean)\",\n",
    "                        taxa=[\"Agaricales\", \"Asparagales\", \"Asterales\"])\n",
    "\n",
    "collected_stats_scatter(os.environ[\"STORAGE_DIR\"], \"out.csv\", os.path.join(os.environ[\"STORAGE_DIR\"], \"Graphs\"), \"png\", \"Images (log)\", \"F1 (mean)\",\n",
    "                        taxa=[\"Coleoptera\",\"Diptera\",\"Lecanorales\"])\n",
    "\n",
    "collected_stats_scatter(os.environ[\"STORAGE_DIR\"], \"out.csv\", os.path.join(os.environ[\"STORAGE_DIR\"], \"Graphs\"), \"png\", \"Images (log)\", \"F1 (mean)\",\n",
    "                        taxa=[\"Lepidoptera\", \"Odonata\", \"Polyporales\"])\n",
    "\n",
    "collected_stats_scatter(os.environ[\"STORAGE_DIR\"], \"out.csv\", os.path.join(os.environ[\"STORAGE_DIR\"], \"Graphs\"), \"svg\", \"img per obs\", \"F1 (mean)\",\n",
    "                        taxa=[\"Anseriformes\", \"Charadriiformes\", \"Passeriformes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train LASSO models an gather metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.regression import lasso\n",
    "\n",
    "lasso(os.environ[\"STORAGE_DIR\"], y=\"F1 (mean)\", x=['Images (log)'])\n",
    "\n",
    "lasso(os.environ[\"STORAGE_DIR\"], y=\"F1 (mean)\", x=['Habitat', 'HWI', 'Body mass (log)', 'Images (log)'])\n",
    "lasso(os.environ[\"STORAGE_DIR\"], y=\"F1 (mean)\", x=['info pixels (log)', 'Images (log)'])\n",
    "lasso(os.environ[\"STORAGE_DIR\"], y=\"F1 (mean)\", x=['Proportion AO vs TOVe', 'Proportion AO+img vs AO', 'img per obs', 'Images (log)'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather bird metrics (using the scatterplots with regressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_stats_scatter(os.environ[\"STORAGE_DIR\"], \"out.csv\", os.path.join(os.environ[\"STORAGE_DIR\"], \"Graphs\"), \"svg\", \"img per obs\", \"Proportion AO+img vs AO\",\n",
    "                        taxa=[\"Anseriformes\", \"Charadriiformes\", \"Passeriformes\"])\n",
    "\n",
    "collected_stats_scatter(os.environ[\"STORAGE_DIR\"], \"out.csv\", os.path.join(os.environ[\"STORAGE_DIR\"], \"Graphs\"), \"svg\", \"Proportion AO+img vs AO\", \"F1 (mean)\",\n",
    "                        taxa=[\"Anseriformes\", \"Charadriiformes\", \"Passeriformes\"])\n",
    "\n",
    "collected_stats_scatter(os.environ[\"STORAGE_DIR\"], \"out.csv\", os.path.join(os.environ[\"STORAGE_DIR\"], \"Graphs\"), \"svg\", \"Habitat\", \"info pixels (log)\",\n",
    "                        taxa=[\"Anseriformes\", \"Charadriiformes\", \"Passeriformes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare numbers of species in the official taxonomy and the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.retrieve_species_characteristics import count_species\n",
    "\n",
    "dwca_file = os.path.join(os.getenv('STORAGE_DIR'), 'GBIF.zip')  # The path to the DwCA file with all data.\n",
    "\n",
    "count_species(os.path.join(os.getenv(\"TAXONOMY_DIR\"), 'Animalia.csv'), dwca=dwca_file, order=[\"Anseriformes\", \"Charadriiformes\", \"Passeriformes\"])\n",
    "count_species(os.path.join(os.getenv(\"TAXONOMY_DIR\"), 'Animalia.csv'), dwca=dwca_file, order=[\"Diptera\"])\n",
    "\n",
    "count_species(os.path.join(os.getenv(\"TAXONOMY_DIR\"), 'Animalia.csv'), dwca=dwca_file, order=[\"Coleoptera\"])\n",
    "count_species(os.path.join(os.getenv(\"TAXONOMY_DIR\"), 'Animalia.csv'), dwca=dwca_file, order=[\"Lepidoptera\"])\n",
    "count_species(os.path.join(os.getenv(\"TAXONOMY_DIR\"), 'Animalia.csv'), dwca=dwca_file, order=[\"Odonata\"])\n",
    "count_species(os.path.join(os.getenv(\"TAXONOMY_DIR\"), 'Fungi.csv'), dwca=dwca_file, order=[\"Lecanorales\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af4db0315b5602c2e778214967c806056e6611e36f3427acd245c2d1613f903f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Ensemble')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
